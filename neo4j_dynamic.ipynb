{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9f82610",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "from langchain_community.graphs import Neo4jGraph\n",
    "# from neo4j_graphrag import Text2Graph\n",
    "from langchain_neo4j import Neo4jVector\n",
    "from langchain_neo4j import GraphCypherQAChain, Neo4jGraph\n",
    "from langchain_neo4j import Neo4jGraph\n",
    "from langchain_experimental.graph_transformers.diffbot import DiffbotGraphTransformer\n",
    "from neo4j_graphrag.experimental.pipeline.kg_builder import SimpleKGPipeline\n",
    "from langchain_neo4j import GraphCypherQAChain\n",
    "# from langchain.graphs.neo4j_graph import Neo4jGraph\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9f386ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "11e1c574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://dereistic-ta-unrobustly.ngrok-free.dev'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getenv(\"NGROK_URL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bf3c3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cd5a71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "453e24db",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OllamaLLM(model=\"gpt-oss:20b-cloud\")\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af26e94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from neo4j import GraphDatabase\n",
    "graph = Neo4jGraph(\n",
    "    url=os.getenv(\"URL\"),\n",
    "    username=os.getenv(\"USERNAME\"),\n",
    "    password=os.getenv(\"PASSWORD\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "35c6a807",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_cypher = GraphCypherQAChain.from_llm(llm=model, graph=graph, verbose=True,allow_dangerous_requests = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e0260a",
   "metadata": {},
   "source": [
    "## Not Cool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8860e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94ae6c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"Can you read anything from this {chain_cypher}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799eb00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ollama.generate(model='gpt-oss:20b', prompt=prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a16586f",
   "metadata": {},
   "source": [
    "## USing the colab version of ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5cb76fff",
   "metadata": {},
   "outputs": [
    {
     "ename": "ResponseError",
     "evalue": "The endpoint dereistic-ta-unrobustly.ngrok-free.dev is offline.\r\n\r\nERR_NGROK_3200\r\n (status code: 404)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mResponseError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mollama\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Client\n\u001b[32m      3\u001b[39m client = Client(host=os.getenv(\u001b[33m\"\u001b[39m\u001b[33mNGROK_URL\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mministral-3:14b\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHello\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(response[\u001b[33m\"\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/aumoza/Strg_1/Freelance/personal/Knowledge-Graphs-Neo/venv/lib/python3.13/site-packages/ollama/_client.py:365\u001b[39m, in \u001b[36mClient.chat\u001b[39m\u001b[34m(self, model, messages, tools, stream, think, logprobs, top_logprobs, format, options, keep_alive)\u001b[39m\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mchat\u001b[39m(\n\u001b[32m    319\u001b[39m   \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    320\u001b[39m   model: \u001b[38;5;28mstr\u001b[39m = \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    330\u001b[39m   keep_alive: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    331\u001b[39m ) -> Union[ChatResponse, Iterator[ChatResponse]]:\n\u001b[32m    332\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    333\u001b[39m \u001b[33;03m  Create a chat response using the requested model.\u001b[39;00m\n\u001b[32m    334\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    363\u001b[39m \u001b[33;03m  Returns `ChatResponse` if `stream` is `False`, otherwise returns a `ChatResponse` generator.\u001b[39;00m\n\u001b[32m    364\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m365\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    366\u001b[39m \u001b[43m    \u001b[49m\u001b[43mChatResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mPOST\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    368\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/api/chat\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    369\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatRequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    370\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_copy_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m      \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_copy_tools\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m      \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m      \u001b[49m\u001b[43mthink\u001b[49m\u001b[43m=\u001b[49m\u001b[43mthink\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m      \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m      \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m      \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[43m      \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_dump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexclude_none\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/aumoza/Strg_1/Freelance/personal/Knowledge-Graphs-Neo/venv/lib/python3.13/site-packages/ollama/_client.py:189\u001b[39m, in \u001b[36mClient._request\u001b[39m\u001b[34m(self, cls, stream, *args, **kwargs)\u001b[39m\n\u001b[32m    185\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(**part)\n\u001b[32m    187\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(**\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m.json())\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/aumoza/Strg_1/Freelance/personal/Knowledge-Graphs-Neo/venv/lib/python3.13/site-packages/ollama/_client.py:133\u001b[39m, in \u001b[36mClient._request_raw\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    131\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m r\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.HTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ResponseError(e.response.text, e.response.status_code) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    134\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.ConnectError:\n\u001b[32m    135\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(CONNECTION_ERROR_MESSAGE) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mResponseError\u001b[39m: The endpoint dereistic-ta-unrobustly.ngrok-free.dev is offline.\r\n\r\nERR_NGROK_3200\r\n (status code: 404)"
     ]
    }
   ],
   "source": [
    "from ollama import Client\n",
    "\n",
    "client = Client(host=os.getenv(\"NGROK_URL\"))\n",
    "\n",
    "response = client.chat(\n",
    "    model=\"ministral-3:14b\",\n",
    "    messages=[{\"role\": \"user\", \"content\": \"Hello\"}]\n",
    ")\n",
    "\n",
    "print(response[\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548510b4",
   "metadata": {},
   "source": [
    "## Asking questions based on the knowledge graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "761ba5b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (p:Person)-[r:WORKS_AT]->(c:Company)\n",
      "WHERE c.name = \"Moon Finance\" AND r.role = \"CTO\"\n",
      "RETURN p.name;\u001b[0m\n",
      "Full Context:\n",
      "\u001b[32;1m\u001b[1;3m[{'p.name': 'Soumil Binani'}]\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "question = \"Who is the CTO of Moon Finance?\"\n",
    "result = chain_cypher.invoke({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8fe9f566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': 'Who is the CTO of Moon Finance?', 'result': 'Soumil Binani.'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "86f5461a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Aum, Soumil Binani.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "be7cb229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I don't know the answer.\n"
     ]
    }
   ],
   "source": [
    "print(result[\"result\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b28095",
   "metadata": {},
   "source": [
    "## Inserting new memories :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb185a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_memory = \"Albert Einstien had a girlfriend named Sofia\"\n",
    "documents = [Document(page_content=new_memory)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "880e0b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_transformer = LLMGraphTransformer(llm=model)\n",
    "# graph_documents = await graph_transformer.aconvert_to_graph_documents(documents)\n",
    "# graph_documents = await graph_transformer.aconvert_to_graph_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5f58763f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'get'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m graph_documents = \u001b[38;5;28;01mawait\u001b[39;00m graph_transformer.aconvert_to_graph_documents(documents)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/aumoza/Strg_1/Moon Finance/Knowledge-Graphs/venv/lib/python3.13/site-packages/langchain_experimental/graph_transformers/llm.py:1031\u001b[39m, in \u001b[36mLLMGraphTransformer.aconvert_to_graph_documents\u001b[39m\u001b[34m(self, documents, config)\u001b[39m\n\u001b[32m   1024\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1025\u001b[39m \u001b[33;03mAsynchronously convert a sequence of documents into graph documents.\u001b[39;00m\n\u001b[32m   1026\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1027\u001b[39m tasks = [\n\u001b[32m   1028\u001b[39m     asyncio.create_task(\u001b[38;5;28mself\u001b[39m.aprocess_response(document, config))\n\u001b[32m   1029\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m document \u001b[38;5;129;01min\u001b[39;00m documents\n\u001b[32m   1030\u001b[39m ]\n\u001b[32m-> \u001b[39m\u001b[32m1031\u001b[39m results = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.gather(*tasks)\n\u001b[32m   1032\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/media/aumoza/Strg_1/Moon Finance/Knowledge-Graphs/venv/lib/python3.13/site-packages/langchain_experimental/graph_transformers/llm.py:957\u001b[39m, in \u001b[36mLLMGraphTransformer.aprocess_response\u001b[39m\u001b[34m(self, document, config)\u001b[39m\n\u001b[32m    953\u001b[39m     parsed_json = [parsed_json]\n\u001b[32m    954\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m rel \u001b[38;5;129;01min\u001b[39;00m parsed_json:\n\u001b[32m    955\u001b[39m     \u001b[38;5;66;03m# Check if mandatory properties are there\u001b[39;00m\n\u001b[32m    956\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m--> \u001b[39m\u001b[32m957\u001b[39m         \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mrel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m(\u001b[33m\"\u001b[39m\u001b[33mhead\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    958\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m rel.get(\u001b[33m\"\u001b[39m\u001b[33mtail\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    959\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m rel.get(\u001b[33m\"\u001b[39m\u001b[33mrelation\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    960\u001b[39m     ):\n\u001b[32m    961\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    962\u001b[39m     \u001b[38;5;66;03m# Nodes need to be deduplicated using a set\u001b[39;00m\n\u001b[32m    963\u001b[39m     \u001b[38;5;66;03m# Use default Node label for nodes if missing\u001b[39;00m\n",
      "\u001b[31mAttributeError\u001b[39m: 'list' object has no attribute 'get'"
     ]
    }
   ],
   "source": [
    "graph_documents = await graph_transformer.aconvert_to_graph_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b2d95c6",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'coroutine' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mgraph_documents\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m.nodes  \u001b[38;5;66;03m# list of nodes\u001b[39;00m\n\u001b[32m      2\u001b[39m graph_documents[\u001b[32m0\u001b[39m].relationships  \u001b[38;5;66;03m# list of relationships\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: 'coroutine' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "graph_documents[0].nodes  # list of nodes\n",
    "graph_documents[0].relationships  # list of relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "27f75cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "await update_graph_in_neo4j(graph_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2c57e357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes:[Node(id='Sofia', type='Person', properties={}), Node(id='Albert Einstien', type='Person', properties={})]\n",
      "Relationships:[Relationship(source=Node(id='Albert Einstien', type='Person', properties={}), target=Node(id='Sofia', type='Person', properties={}), type='HAS_GIRLFRIEND', properties={})]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Nodes:{graph_documents[0].nodes}\")\n",
    "print(f\"Relationships:{graph_documents[0].relationships}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40e6591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aiyo KG hatt naa jaye puraka pura:\n",
    "summary = driver.execute_query(cypher_query_manual, database_=\"neo4j\").summary\n",
    "print(\"Created {nodes_created} nodes in {time} ms.\".format(\n",
    "    nodes_created=summary.counters.nodes_created,\n",
    "    time=summary.result_available_after\n",
    "))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
